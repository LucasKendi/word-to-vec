{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\envs\\word2vec\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#imports shit\n",
    "from __future__ import unicode_literals\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads shit\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines some shit\n",
    "\n",
    "def vec(s):\n",
    "    return nlp.vocab[s].vector\n",
    "\n",
    "def word(s):\n",
    "    return nlp.vocab[s]\n",
    "\n",
    "def subv(coord1, coord2):\n",
    "    return [c1 - c2 for c1, c2 in zip(coord1, coord2)]\n",
    "\n",
    "def addv(coord1, coord2):\n",
    "    return [c1 + c2 for c1, c2 in zip(coord1, coord2)]\n",
    "\n",
    "#calculates mean of words, accept a list of words\n",
    "def meanv(coords):\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean\n",
    "\n",
    "#finds closest words to result value\n",
    "def spacy_closest(result):\n",
    "    computed_similarities = []\n",
    "    cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)    \n",
    "    for word in nlp.vocab:\n",
    "        # Ignore words without vectors\n",
    "        if not word.has_vector:\n",
    "            continue\n",
    "\n",
    "        similarity = cosine_similarity(result, word.vector)\n",
    "        computed_similarities.append((word, similarity))\n",
    "\n",
    "    computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "    print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36454636\n",
      "0.26219127\n",
      "0.32917053\n"
     ]
    }
   ],
   "source": [
    "imposto  = word(\"tax\")\n",
    "roubo = word(\"theft\")\n",
    "bom = word(\"good\")\n",
    "ruim = word(\"bad\")\n",
    "print(imposto.similarity(roubo))\n",
    "print(imposto.similarity(bom))\n",
    "print(imposto.similarity(ruim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hardwood', 'particleboard', 'SAWDUST', 'NON-WOOD', 'sawn', 'TIMBERS', 'veneer', 'TIMBER', 'Timber', 'firewood']\n",
      "75.54003310203552\n"
     ]
    }
   ],
   "source": [
    "my_word = meanv([vec(\"wood\"), vec(\"fire\")])\n",
    "curr = time.time()\n",
    "spacy_closest(my_word)\n",
    "print(time.time() - curr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
